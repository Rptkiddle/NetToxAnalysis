{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61f8852c-ef61-47de-a367-b1e9ae9ec39f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. merge toxicity data with source dataset. \n",
    "\n",
    "This workbook merges the toxicity classifications produces in 2_classify.py with the original messaging/post dataset.\n",
    "\n",
    "- **INPUTS:** the following input files must be in the data directory:\n",
    "    - `tox.json` (toxicity classification data output from `2_classify.py`)\n",
    "    - `source.csv` (original timeseries dataset input to `1_prepare.ipynb`)\n",
    "    \n",
    "- **OUTPUTS:** this workbook saves the following files in the data directory:\n",
    "    - `merged.csv` (merged toxicity classification and timeseries dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc683bd-dbc9-4a3b-a74f-7b7e6f49ee53",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb88cd3-99ee-46fa-aaca-c6d606ced60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencies:\n",
    "import os\n",
    "import json\n",
    "import ndjson\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "#data directory:\n",
    "datadir = os.getcwd()+'/../../data/'\n",
    "\n",
    "#declare name of toxicity classifications file:\n",
    "toxicity_file = 'tox.json'\n",
    "\n",
    "#declare name of source file (i.e, messaging or post data): \n",
    "source_file = 'source.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e46d54-d367-4ed3-971d-980b4e02510d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## prepare data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae39e66-2ba6-4cc9-bc4f-670e799e964b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### generate dataframe from toxicity classification data::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3944f13-7f16-42f5-af5b-755b0c5bca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import toxicity data:\n",
    "classifications = []\n",
    "with open(datadir+toxicity_file) as f:\n",
    "        data = ndjson.load(f)\n",
    "        classifications.extend(data)\n",
    "\n",
    "#convert to dataframe:\n",
    "message, toxicity, language, status = [], [], [], []\n",
    "\n",
    "for classification in classifications:\n",
    "    \n",
    "    if type(classification['response']) == dict: #i.e. if retrieval was successful..\n",
    "        message.append(classification['message']) #append message\n",
    "        toxicity.append(classification['response']['attributeScores']['TOXICITY']['summaryScore']['value']) #append toxicity score\n",
    "        language.append(classification['response']['languages']) #append detected language\n",
    "        status.append('retrieved')\n",
    "    \n",
    "    elif type(classification['response']) != dict: #i.e. if retrieval was not successful..\n",
    "        message.append(classification['message']) #append message\n",
    "        toxicity.append(float('nan')) #append NaN for toxicity score\n",
    "        language.append(float('nan')) #append NaN for detected language score\n",
    "        status.append(classification['response']) #append error message. \n",
    "    \n",
    "    else: print(f'unable to process:{classification}, skipping entry..' )\n",
    "\n",
    "classifications_ls = list(zip(message, toxicity, language, status)) #zip together these data\n",
    "\n",
    "classifications_df = pd.DataFrame(classifications_ls, columns=['message','toxicity','language','status']) #form into dataframe (ready to merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec114fb9",
   "metadata": {},
   "source": [
    "### merge toxicity data with original messaging data::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae874504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load messages dataset: \n",
    "messages_full = pd.read_csv(datadir+source_file) \n",
    "\n",
    "#declare the name of the column containing message or post text:\n",
    "messages_col = 'text'\n",
    "\n",
    "#merge datasets:\n",
    "complete = messages_full.merge(classifications_df, how='left', left_on='text', right_on='message') #merge on message text with classifications\n",
    "\n",
    "#confirm results:\n",
    "print(f\"Data for {classifications_df.shape[0]} classification attempts has been mapped to {complete.shape[0]} messages in full dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591930e-27ff-4f85-8cb8-214085b5a997",
   "metadata": {
    "tags": []
   },
   "source": [
    "### check completeness of classifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f116584-94ea-4016-9232-345c9ee54d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many messages failed to classify?\n",
    "subset = complete[complete['toxicity'].isna()]\n",
    "print(f\"There are {len(subset)} messages that were not classified\")\n",
    "\n",
    "#how many of those had to text to begin with?\n",
    "subset = subset[subset['text'].notna()]\n",
    "print(f\"Of these: {len(subset)} messages contained text\")\n",
    "\n",
    "#save local for manual inspection:\n",
    "subset['text'].to_csv(datadir+'unclassified.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4928bccc-a18d-416c-999a-5e0bd637dc86",
   "metadata": {
    "tags": []
   },
   "source": [
    "### set time-series index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95f7fe2-9dca-4db8-8e60-e71f31d7a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare name of column containing date:\n",
    "date_col = 'date'\n",
    "\n",
    "#(if required) reformat date column (str -> datetime): \n",
    "complete['date']= pd.to_datetime(complete[date_col])\n",
    "\n",
    "#set datetimeindex (time series data):\n",
    "complete = complete.set_index(date_col)\n",
    "\n",
    "#sort by date:\n",
    "complete = complete.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c12a52-3190-4f38-beb5-0aea4d6f2599",
   "metadata": {},
   "source": [
    "### select for required data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19168e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print column names:\n",
    "print(complete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fbd6cf-0afd-429f-8ee4-9fa07cad7849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(optional) specify columns to retain:\n",
    "keep_cols = ['source', 'type', 'message', 'toxicity', 'language', 'status']\n",
    "\n",
    "#filter columns, drop all rows missing toxicity score.\n",
    "data = complete.filter(keep_cols).dropna(subset=['toxicity'])\n",
    "\n",
    "#(optional) filter for some date range: \n",
    "start_date = '2021-01-01'\n",
    "end_date = '2022-12-31'\n",
    "data = data.loc[start_date:end_date]\n",
    "\n",
    "#(optional) filter for entities with some minimum number of (classified) messages:\n",
    "entity_column_name = 'source'\n",
    "minimum_classified_count = 1\n",
    "subset = data.groupby(entity_column_name).filter(lambda x: len(x) >= minimum_classified_count)\n",
    "\n",
    "#export this data for re-sampling\n",
    "subset.to_csv(datadir+'merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24df9a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled = pd.read_csv(datadir+'resampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eceedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f57ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('scratch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "435370adf77703aea1b8e572effd6e7704a84dcbbb2e582aa618133564cbd1e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
